{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G7NagJHQqwA",
        "outputId": "84342088-de86-4511-822b-51782b2e1bf1"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVzGWP1jQybC",
        "outputId": "170429eb-d7d4-433e-9ba1-81aad929f7ee"
      },
      "outputs": [],
      "source": [
        "!unzip copnn.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Eq2Bn_TM0l",
        "outputId": "481204b4-3ce8-497f-c7db-32088d278c92"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4C2a-89R8Lk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7xQLLcaSB49"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "from copnn.regression import run_regression\n",
        "from copnn.simulation import Count\n",
        "from copnn.modes.spatial_categorical import SpatialCategorical\n",
        "from copnn.distributions import get_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Y_WCvHSMMu"
      },
      "outputs": [],
      "source": [
        "# Used Cars from Craigslist dataset from Kaggle: https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data\n",
        "# Run cars_etl.R script\n",
        "cars = pd.read_csv('../data/cars_df5.csv')\n",
        "cols_to_drop = ['location_id']\n",
        "cars.drop(cols_to_drop, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "GMplhch4ScPL",
        "outputId": "f43836be-6a4a-4024-a192-b23b06b25a2b"
      },
      "outputs": [],
      "source": [
        "print(cars.shape)\n",
        "cars.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "O09oToptShdV",
        "outputId": "a78aa5ec-be5c-477d-d3ec-06c8be0c3f20"
      },
      "outputs": [],
      "source": [
        "cars['price'].plot(kind='hist', bins = 20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "S_cZwfnaSmaN",
        "outputId": "c137ceb5-a7dc-4699-9ef7-497fe6a40e5e"
      },
      "outputs": [],
      "source": [
        "cars['price'] = np.log(cars['price'])\n",
        "cars['price'].plot(kind='hist', bins = 20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neutBStOuv-3"
      },
      "outputs": [],
      "source": [
        "cars[['lat', 'long']] = cars[['lat', 'long']].round(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "465GyUbiSprT",
        "outputId": "5a9ff0e1-bbf3-4383-bb6a-fc9d662fd1ac"
      },
      "outputs": [],
      "source": [
        "cars.groupby(['lat', 'long']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "FY8Z-3QBv_Xi",
        "outputId": "58d3737e-c43e-4635-ea2d-d91e0a8db3a3"
      },
      "outputs": [],
      "source": [
        "location_df = cars.groupby(['lat', 'long']).size().index.to_frame()\n",
        "location_df['location_id'] = np.arange(location_df.shape[0])\n",
        "location_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo4R5uMJwMLK",
        "outputId": "9b060286-fe69-4e63-fc20-d14da6586a91"
      },
      "outputs": [],
      "source": [
        "cars['id'] = np.arange(cars.shape[0])\n",
        "cars = cars.set_index(['lat', 'long']).join(location_df[['location_id']]).reset_index().sort_values(by=['id']).drop(['id'], axis=1)\n",
        "cars.index = np.arange(cars.shape[0])\n",
        "cars.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CvZFLZK_wtdB",
        "outputId": "9318f073-ab46-467f-99e2-17caa64b5fbc"
      },
      "outputs": [],
      "source": [
        "cars[['lat', 'long', 'location_id']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JNIN-3vSton",
        "outputId": "183a309b-368b-4084-ba91-88c4977939da"
      },
      "outputs": [],
      "source": [
        "print(len(cars['location_id'].unique()))\n",
        "print(cars['location_id'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKe6pAmvSxY6",
        "outputId": "5713dc75-6874-45a0-9da3-173efebf00c5"
      },
      "outputs": [],
      "source": [
        "print(len(cars['model_id'].unique()))\n",
        "print(cars['model_id'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tggaJeATS7Y0",
        "outputId": "54c154c4-4f15-4a98-f826-1c5e1627d050"
      },
      "outputs": [],
      "source": [
        "coords = cars.groupby(['location_id','lat', 'long']).size().index.to_frame().values\n",
        "coords[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5XgoXmdS9nO",
        "outputId": "1c1e9831-7552-4ea9-c0b5-627a198666eb"
      },
      "outputs": [],
      "source": [
        "dist_matrix = squareform(pdist(coords[:,1:])) ** 2\n",
        "dist_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFG_HZnUTUw8"
      },
      "outputs": [],
      "source": [
        "cars.rename({'lat': 'D1', 'long': 'D2', 'location_id': 'z0', 'model_id': 'z1'}, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPfuXrYjTAUa",
        "outputId": "a40ad6ad-9485-4bbc-cf5b-2e247c301508"
      },
      "outputs": [],
      "source": [
        "cars.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmjlN4vU2jN0"
      },
      "outputs": [],
      "source": [
        "def get_mode(mode_par):\n",
        "  if mode_par == 'categorical':\n",
        "      mode = Categorical()\n",
        "  elif mode_par == 'longitudinal':\n",
        "      mode = Longitudinal()\n",
        "  elif mode_par == 'spatial':\n",
        "      mode = Spatial()\n",
        "  elif mode_par == 'spatial_categorical':\n",
        "      mode = SpatialCategorical()\n",
        "  else:\n",
        "      raise NotImplementedError(f'{mode_par} mode not implemented.')\n",
        "  return mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlO1Czeg2o8L"
      },
      "outputs": [],
      "source": [
        "y_type = 'continuous'\n",
        "mode = get_mode('spatial_categorical')\n",
        "batch = 100\n",
        "epochs = 200\n",
        "patience = None\n",
        "n_sig2bs = 1\n",
        "n_sig2bs_spatial = 2\n",
        "est_cors = []\n",
        "n_neurons = [10, 3]\n",
        "activation = 'relu'\n",
        "dropout = []\n",
        "spatial_embedded_neurons = []\n",
        "qs = [len(cars['z1'].unique())]\n",
        "q_spatial = len(cars['z0'].unique())\n",
        "Z_non_linear = False\n",
        "Z_embed_dim_pct = 10\n",
        "time2measure_dict = None\n",
        "pred_future = False # change this for future mode in longitudinal data\n",
        "spatial_embed_neurons = None\n",
        "resolution = None\n",
        "verbose = True\n",
        "log_params = False\n",
        "idx = None\n",
        "shuffle = False\n",
        "b_true = None\n",
        "distributions = ['laplace', 'gumbel', 'loggamma', 'logistic', 'skewnorm']\n",
        "pred_unknown_clusters = True # change this for unknown locations in test in spatial data\n",
        "sample_n_train = 30000 # make sure sample_n_train is on the maximum it can get, I got to 30K (default 10K)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCIs4de_UdIP"
      },
      "outputs": [],
      "source": [
        "res = pd.DataFrame(columns=['experiment', 'distribution', 'exp_type', 'mse_no_re', 'mse', 'sigma_e_est',\n",
        "                            'sigma_b0_est', 'sigma_b0_est_spatial', 'sigma_b1_est_spatial', 'rho_est',\n",
        "                            'nll_tr', 'nll_te', 'n_epoch', 'time'])\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "counter = Count().gen()\n",
        "\n",
        "X, y = cars.drop(['price'], axis=1), cars['price']\n",
        "\n",
        "x_cols = [col for col in X.columns if col not in ['z0', 'z1']]\n",
        "x_cols_to_scale = [col for col in x_cols if col not in ['D1', 'D2']]\n",
        "file_name = 'res_cars_copnn.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7fVuxq2VfkS"
      },
      "outputs": [],
      "source": [
        "def iterate_reg_types(X_train, X_test, y_train, y_test, counter, i, verbose):\n",
        "    print(f'  started ignore...')\n",
        "    res_ignore = run_regression(\n",
        "        X_train, X_test, y_train, y_test, qs, q_spatial, x_cols,\n",
        "        batch, epochs, patience, n_neurons, dropout, activation, 'ignore',\n",
        "        Z_non_linear, Z_embed_dim_pct, mode, y_type, n_sig2bs, n_sig2bs_spatial, est_cors,\n",
        "        dist_matrix, time2measure_dict, spatial_embed_neurons, resolution, verbose,\n",
        "        log_params, idx, shuffle, None, b_true)\n",
        "    print('  finished ignore, mse: %.3f' % res_ignore.metric_mse)\n",
        "    res.loc[next(counter)] = [i, 'gaussian', 'ignore', res_ignore.metric_mse_no_re, res_ignore.metric_mse,\n",
        "                              None, None, None, None, res_ignore.sig_ratio,\n",
        "                              res_ignore.nll_tr, res_ignore.nll_te, res_ignore.n_epochs, res_ignore.time]\n",
        "    print(f'  skipping ohe...')\n",
        "    # res_ohe = run_regression(\n",
        "    #     X_train, X_test, y_train, y_test, qs, q_spatial, x_cols,\n",
        "    #     batch, epochs, patience, n_neurons, dropout, activation, 'ohe',\n",
        "    #     Z_non_linear, Z_embed_dim_pct, mode, y_type, n_sig2bs, n_sig2bs_spatial, est_cors,\n",
        "    #     dist_matrix, time2measure_dict, spatial_embed_neurons, resolution, verbose,\n",
        "    #     log_params, idx, shuffle, None, b_true)\n",
        "    # print('  finished ohe, mse: %.3f' % res_ohe.metric_mse)\n",
        "    # res.loc[next(counter)] = [i, 'gaussian', 'ohe', res_ohe.metric_mse_no_re, res_ohe.metric_mse,\n",
        "    #                           None, None, None, None, res_ohe.sig_ratio,\n",
        "    #                           res_ohe.nll_tr, res_ohe.nll_te, res_ohe.n_epochs, res_ohe.time]\n",
        "    print(f'  started embedding...')\n",
        "    res_embed = run_regression(\n",
        "        X_train, X_test, y_train, y_test, qs, q_spatial, x_cols,\n",
        "        batch, epochs, patience, n_neurons, dropout, activation, 'embed',\n",
        "        Z_non_linear, Z_embed_dim_pct, mode, y_type, n_sig2bs, n_sig2bs_spatial, est_cors,\n",
        "        dist_matrix, time2measure_dict, spatial_embed_neurons, resolution, verbose,\n",
        "        log_params, idx, shuffle, None, b_true)\n",
        "    print('  finished embed, mse: %.3f' % res_embed.metric_mse)\n",
        "    res.loc[next(counter)] = [i, 'gaussian', 'embed', res_embed.metric_mse_no_re, res_embed.metric_mse,\n",
        "                              None, None, None, None, res_embed.sig_ratio,\n",
        "                              res_embed.nll_tr, res_embed.nll_te, res_embed.n_epochs, res_embed.time]\n",
        "    print(f'  started lmmnn...')\n",
        "    res_lmmnn = run_regression(\n",
        "        X_train, X_test, y_train, y_test, qs, q_spatial, x_cols,\n",
        "        batch, epochs, patience, n_neurons, dropout, activation, 'lmmnn',\n",
        "        Z_non_linear, Z_embed_dim_pct, mode, y_type, n_sig2bs, n_sig2bs_spatial, est_cors,\n",
        "        dist_matrix, time2measure_dict, spatial_embed_neurons, resolution, verbose,\n",
        "        log_params, idx, shuffle, None, b_true, sample_n_train = sample_n_train)\n",
        "    print('  finished lmmnn, mse: %.3f' % res_lmmnn.metric_mse)\n",
        "    res.loc[next(counter)] = [i, 'gaussian', 'lmmnn', res_lmmnn.metric_mse_no_re, res_lmmnn.metric_mse,\n",
        "                              res_lmmnn.sigmas[0], res_lmmnn.sigmas[1][0], res_lmmnn.sigmas[2][0], res_lmmnn.sigmas[2][1], res_lmmnn.sig_ratio,\n",
        "                              res_lmmnn.nll_tr, res_lmmnn.nll_te, res_lmmnn.n_epochs, res_lmmnn.time]\n",
        "    for fit_dist in distributions:\n",
        "        fit_dist = get_distribution(fit_dist)\n",
        "        print(f'  started copnn with marginal: {fit_dist}...')\n",
        "        res_copnn = run_regression(\n",
        "            X_train, X_test, y_train, y_test, qs, q_spatial, x_cols,\n",
        "            batch, epochs, patience, n_neurons, dropout, activation, 'copnn',\n",
        "            Z_non_linear, Z_embed_dim_pct, mode, y_type, n_sig2bs, n_sig2bs_spatial, est_cors,\n",
        "            dist_matrix, time2measure_dict, spatial_embed_neurons, resolution, verbose,\n",
        "            log_params, idx, shuffle, fit_dist, b_true, sample_n_train = sample_n_train)\n",
        "        print(f'  finished copnn dist {fit_dist}, mse: {res_copnn.metric_mse: .3f}')\n",
        "        res.loc[next(counter)] = [i, fit_dist, 'copnn', res_copnn.metric_mse_no_re, res_copnn.metric_mse,\n",
        "                                  res_copnn.sigmas[0], res_copnn.sigmas[1][0], res_copnn.sigmas[2][0], res_copnn.sigmas[2][1], res_copnn.sig_ratio,\n",
        "                                  res_copnn.nll_tr, res_copnn.nll_te, res_copnn.n_epochs, res_copnn.time]\n",
        "    res.to_csv(f'drive/MyDrive/copnn_experiments/{file_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YTH788PWgv0"
      },
      "outputs": [],
      "source": [
        "if not pred_unknown_clusters:\n",
        "  for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
        "    print('iteration %d' % i)\n",
        "    X_train, X_test, y_train, y_test = X.loc[train_index].copy(), X.loc[test_index].copy(), y[train_index], y[test_index]\n",
        "    # scaler = StandardScaler()\n",
        "    # X_train[x_cols_to_scale] = scaler.fit_transform(X_train[x_cols_to_scale])\n",
        "    # X_test[x_cols_to_scale] = scaler.transform(X_test[x_cols_to_scale])\n",
        "    iterate_reg_types(X_train, X_test, y_train, y_test, counter, i, verbose)\n",
        "else:\n",
        "  for i, (train_clusters, test_clusters) in enumerate(kf.split(range(q_spatial))):\n",
        "    print('iteration %d' % i)\n",
        "    X_train, X_test = X[X['z0'].isin(train_clusters)], X[X['z0'].isin(test_clusters)]\n",
        "    train_index, test_index = X_train.index, X_test.index\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    print(X_train.shape[0], X_test.shape[0])\n",
        "    print(y_train.shape[0], y_test.shape[0])\n",
        "    print(X_train['z0'].unique().shape, X_test['z0'].unique().shape)\n",
        "    # scaler = StandardScaler()\n",
        "    # X_train[x_cols_to_scale] = scaler.fit_transform(X_train[x_cols_to_scale])\n",
        "    # X_test[x_cols_to_scale] = scaler.transform(X_test[x_cols_to_scale])\n",
        "    iterate_reg_types(X_train, X_test, y_train, y_test, counter, i, verbose)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
